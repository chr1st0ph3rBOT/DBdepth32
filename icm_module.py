# icm_module.py
import torch
import torch.nn as nn

class ICM(nn.Module):
    def __init__(self, obs_shape, action_dim, feature_dim=256):
        """
        obs_shape: ê´€ì¸¡ ìƒíƒœì˜ ì´ë¯¸ì§€ í¬ê¸° (ì˜ˆ: (3, 96, 96))
        action_dim: í–‰ë™ ë²¡í„° ì°¨ì› ìˆ˜ (ì˜ˆ: 4)
        feature_dim: CNNìœ¼ë¡œ ì¶”ì¶œí•  ìƒíƒœ ì„ë² ë”© í¬ê¸° (ê¸°ë³¸ 256)
        """
        super(ICM, self).__init__()
        
        c, h, w = obs_shape  # ì±„ë„, ë†’ì´, ë„ˆë¹„

        # ğŸ§  ìƒíƒœ ì¸ì½”ë” (ì´ë¯¸ì§€ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ì••ì¶•)
        self.encoder = nn.Sequential(
            nn.Conv2d(c, 32, kernel_size=8, stride=4),  # 96 â†’ 23 kernelì€ í•„í„°ì„ì„
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=4, stride=2), # 23 â†’ 10
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, stride=1), # 10 â†’ 8
            nn.ReLU(),
            nn.Flatten(),
            nn.Linear(64 * 8 * 8, feature_dim),  # CNN ì¶œë ¥ â†’ FC â†’ feature_dim í¬ê¸°
            nn.ReLU()
        )

        # ğŸ”® Forward Model: (í˜„ì¬ ìƒíƒœ, í–‰ë™) â†’ ë‹¤ìŒ ìƒíƒœ ì˜ˆì¸¡
        self.forward = nn.Sequential(
            nn.Linear(feature_dim + action_dim, 256),
            nn.ReLU(),
            nn.Linear(256, feature_dim)
        )

    def forward_loss(self, state, next_state, action):
        """
        ìƒíƒœ ì „ì´ ì˜ˆì¸¡ ê¸°ë°˜ intrinsic reward ê³„ì‚°
        - ì…ë ¥: í˜„ì¬ ìƒíƒœ, ë‹¤ìŒ ìƒíƒœ, í–‰ë™
        - ì¶œë ¥: ì˜ˆì¸¡ ì‹¤íŒ¨ ì •ë„ (ë³´ìƒ ê°’ìœ¼ë¡œ ì‚¬ìš©)
        """

        # â–¶ï¸ ë‹¤ìŒ ìƒíƒœë¥¼ ì¸ì½”ë”© (ì •ë‹µ ì—­í• )
        with torch.no_grad():  # íƒ€ê²Ÿì€ í•™ìŠµí•˜ì§€ ì•ŠìŒ
            phi_next = self.encoder(next_state)

        # â–¶ï¸ í˜„ì¬ ìƒíƒœë„ ì¸ì½”ë”©
        phi = self.encoder(state)

        # â–¶ï¸ ìƒíƒœ ì„ë² ë”© + í–‰ë™ ê²°í•© â†’ ë‹¤ìŒ ìƒíƒœ ì˜ˆì¸¡
        input_fwd = torch.cat([phi, action], dim=1)
        phi_next_pred = self.forward(input_fwd)

        # â–¶ï¸ ì˜ˆì¸¡ê³¼ ì‹¤ì œì˜ ì°¨ì´ = ë³´ìƒ (ì˜ˆì¸¡ì´ ì–´ë ¤ìš¸ìˆ˜ë¡ ë³´ìƒì´ í¼)
        loss = ((phi_next - phi_next_pred) ** 2).mean(dim=1)

        return loss  # shape: [batch_size] (ê° transition ë‹¹ ë³´ìƒ)
